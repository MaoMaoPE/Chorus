/* Generated by: JavaCC 21 Parser Generator. SNBTLexer.java */
package org.chorus.nbt.snbt

import org.chorus.nbt.snbt.SNBTConstants.LexicalState
import org.chorus.nbt.snbt.SNBTNfaData.NfaFunction
import java.io.*
import java.nio.Buffer
import java.nio.ByteBuffer
import java.nio.CharBuffer
import java.nio.charset.*
import java.util.*
import kotlin.math.max

class SNBTLexer @JvmOverloads constructor(
    inputSource: String,
    input: CharSequence,
    lexState: LexicalState = LexicalState.SNBT,
    startingLine: Int = 1,
    startingColumn: Int = 1
) :
    SNBTConstants {
    private var tabSize = DEFAULT_TAB_SIZE

    /**
     * set the tab size used for location reporting
     */
    fun setTabSize(tabSize: Int) {
        this.tabSize = tabSize
    }

    val DUMMY_START_TOKEN: Token = Token()

    // Munged content, possibly replace unicode escapes, tabs, or CRLF with LF.
    private var content: CharSequence? = null

    // The source of the raw characters that we are scanning  
    // Typically a filename, I suppose.
    var inputSource: String = "input"

    // A list of offsets of the beginning of lines
    private var lineOffsets: IntArray

    // The starting line and column, usually 1,1
    // that is used to report a file position 
    // in 1-based line/column terms
    private var startingLine = 0
    private var startingColumn = 0

    // The offset in the internal buffer to the very
    // next character that the readChar method returns
    private var bufferPosition = 0

    // A BitSet that stores where the tokens are located.
    // This is not strictly necessary, I suppose...
    private var tokenOffsets: BitSet? = null

    //  A Bitset that stores the line numbers that
    // contain either hard tabs or extended (beyond 0xFFFF) unicode
    // characters.
    private val needToCalculateColumns = BitSet()

    // Just a very simple, bloody minded approach, just store the
    // Token objects in a table where the offsets are the code unit 
    // positions in the content buffer. If the Token at a given offset is
    // the dummy or marker type IGNORED, then the location is skipped via
    // whatever preprocessor logic.    
    private val tokenLocationTable: Array<Token?>

    // The following two BitSets are used to store 
    // the current active NFA states in the core tokenization loop
    private var nextStates = BitSet(76)
    private var currentStates = BitSet(76)
    var activeTokenTypes: EnumSet<SNBTConstants.TokenType> = EnumSet.allOf(
        SNBTConstants.TokenType::class.java
    )


    constructor(input: CharSequence) : this("input", input)

    /**
     * Preferably use the constructor that takes a #java.nio.files.Path or simply a String,
     * depending on your use case
     */
    @Deprecated("")
    constructor(reader: Reader) : this("input", reader, LexicalState.SNBT, 1, 1)

    /**
     * Preferably use the constructor that takes a #java.nio.files.Path or simply a String,
     * depending on your use case
     */
    @Deprecated("")
    constructor(inputSource: String, reader: Reader) : this(inputSource, reader, LexicalState.SNBT, 1, 1)

    /**
     * Preferably use the constructor that takes a #java.nio.files.Path or simply a String,
     * depending on your use case
     */
    @Deprecated("")
    constructor(inputSource: String, reader: Reader, lexState: LexicalState, line: Int, column: Int) : this(
        inputSource,
        readToEnd(reader),
        lexState,
        line,
        column
    ) {
        switchTo(lexState)
    }

    private val nextToken: Token
        get() {
            var invalidToken: InvalidToken? = null
            var token = nextToken()
            while (token is InvalidToken) {
                if (invalidToken == null) {
                    invalidToken = token
                } else {
                    invalidToken.endOffset = token.getEndOffset()
                }
                token = nextToken()
            }
            if (invalidToken != null) cacheToken(invalidToken)
            cacheToken(token)
            if (invalidToken != null) {
                goTo(invalidToken.endOffset)
                return invalidToken
            }
            return token
        }

    /**
     * The public method for getting the next token.
     * If the tok parameter is null, it just tokenizes
     * starting at the internal bufferPosition
     * Otherwise, it checks whether we have already cached
     * the token after this one. If not, it finally goes
     * to the NFA machinery
     */
    fun getNextToken(tok: Token?): Token {
        if (tok == null) {
            return nextToken
        }
        var cachedToken = tok.nextCachedToken()
        // If the cached next token is not currently active, we
        // throw it away and go back to the XXXLexer
        if (cachedToken != null && !activeTokenTypes.contains(cachedToken.type)) {
            reset(tok)
            cachedToken = null
        }
        return cachedToken ?: getNextToken(tok.endOffset)
    }

    /**
     * A lower level method to tokenize, that takes the absolute
     * offset into the content buffer as a parameter
     *
     * @param offset where to start
     * @return the token that results from scanning from the given starting point
     */
    fun getNextToken(offset: Int): Token {
        goTo(offset)
        return nextToken
    }

    // The main method to invoke the NFA machinery
    private fun nextToken(): Token {
        var matchedToken: Token? = null
        var inMore = false
        var tokenBeginOffset = this.bufferPosition
        var firstChar = 0
        // The core tokenization loop
        while (matchedToken == null) {
            var curChar: Int
            var codeUnitsRead = 0
            var matchedPos = 0
            var matchedType: SNBTConstants.TokenType? = null
            var reachedEnd = false
            if (inMore) {
                curChar = readChar()
                if (curChar == -1) reachedEnd = true
            } else {
                tokenBeginOffset = this.bufferPosition
                curChar = readChar()
                firstChar = curChar
                if (curChar == -1) {
                    matchedType = SNBTConstants.TokenType.EOF
                    reachedEnd = true
                }
            }
            // the core NFA loop
            if (!reachedEnd) do {
                // Holder for the new type (if any) matched on this iteration
                var newType: SNBTConstants.TokenType? = null
                if (codeUnitsRead > 0) {
                    // What was nextStates on the last iteration 
                    // is now the currentStates!
                    val temp = currentStates
                    currentStates = nextStates
                    nextStates = temp
                    val retval = readChar()
                    if (retval >= 0) {
                        curChar = retval
                    } else {
                        reachedEnd = true
                        break
                    }
                }
                nextStates.clear()
                var nextActive = if (codeUnitsRead == 0) 0 else currentStates.nextSetBit(0)
                do {
                    val returnedType = nfaFunctions[nextActive]!!
                        .apply(curChar, nextStates, activeTokenTypes)
                    if (returnedType != null && (newType == null || returnedType.ordinal < newType.ordinal)) {
                        newType = returnedType
                    }
                    nextActive = if (codeUnitsRead == 0) -1 else currentStates.nextSetBit(nextActive + 1)
                } while (nextActive != -1)
                ++codeUnitsRead
                if (curChar > 0xFFFF) ++codeUnitsRead
                if (newType != null) {
                    matchedType = newType
                    inMore = moreTokens.contains(matchedType)
                    matchedPos = codeUnitsRead
                }
            } while (!nextStates.isEmpty)
            if (matchedType == null) {
                bufferPosition = tokenBeginOffset + 1
                if (firstChar > 0xFFFF) ++bufferPosition
                return InvalidToken(this, tokenBeginOffset, bufferPosition)
            }
            bufferPosition -= (codeUnitsRead - matchedPos)
            if (skippedTokens.contains(matchedType)) {
                for (i in tokenBeginOffset..<bufferPosition) {
                    if (tokenLocationTable[i] !== IGNORED) tokenLocationTable[i] = SKIPPED
                }
            } else if (regularTokens.contains(matchedType) || unparsedTokens.contains(matchedType)) {
                matchedToken = Token.Companion.newToken(
                    matchedType,
                    this, tokenBeginOffset, bufferPosition
                )
                matchedToken.isUnparsed = !regularTokens.contains(matchedType)
            }
        }
        return matchedToken
    }

    var lexicalState: LexicalState = LexicalState.entries[0]

    /**
     * Switch to specified lexical state.
     *
     * @param lexState the lexical state to switch to
     * @return whether we switched (i.e. we weren't already in the desired lexical state)
     */
    fun switchTo(lexState: LexicalState): Boolean {
        if (this.lexicalState != lexState) {
            this.lexicalState = lexState
            return true
        }
        return false
    }

    // Reset the token source input
    // to just after the Token passed in.
    @JvmOverloads
    fun reset(t: Token, state: LexicalState? = null) {
        goTo(t.endOffset)
        uncacheTokens(t)
        if (state != null) {
            switchTo(state)
        }
    }

    // But there is no goto in Java!!!
    private fun goTo(offset: Int) {
        var offset = offset
        while (offset < content!!.length && tokenLocationTable[offset] === IGNORED) {
            ++offset
        }
        this.bufferPosition = offset
    }

    private fun readChar(): Int {
        while (tokenLocationTable[bufferPosition] === IGNORED && bufferPosition < content!!.length) {
            ++bufferPosition
        }
        if (bufferPosition >= content!!.length) {
            return -1
        }
        val ch = content[bufferPosition++]
        if (Character.isHighSurrogate(ch) && bufferPosition < content.length) {
            val nextChar = content[bufferPosition]
            if (Character.isLowSurrogate(nextChar)) {
                ++bufferPosition
                return Character.toCodePoint(ch, nextChar)
            }
        }
        return ch.code
    }

    /**
     * This is used in conjunction with having a preprocessor.
     * We set which lines are actually parsed lines and the
     * unset ones are ignored.
     *
     * @param parsedLines a #java.util.BitSet that holds which lines
     * are parsed (i.e. not ignored)
     */
    private fun setParsedLines(parsedLines: BitSet, reversed: Boolean) {
        for (i in lineOffsets.indices) {
            var turnOffLine = !parsedLines[i + 1]
            if (reversed) turnOffLine = !turnOffLine
            if (turnOffLine) {
                val lineOffset = lineOffsets[i]
                val nextLineOffset = if (i < lineOffsets.size - 1) lineOffsets[i + 1] else content!!.length
                for (offset in lineOffset..<nextLineOffset) {
                    tokenLocationTable[offset] = IGNORED
                }
            }
        }
    }

    /**
     * This is used in conjunction with having a preprocessor.
     * We set which lines are actually parsed lines and the
     * unset ones are ignored.
     *
     * @param parsedLines a #java.util.BitSet that holds which lines
     * are parsed (i.e. not ignored)
     */
    fun setParsedLines(parsedLines: BitSet) {
        setParsedLines(parsedLines, false)
    }

    fun setUnparsedLines(unparsedLines: BitSet) {
        setParsedLines(unparsedLines, true)
    }

    /**
     * @return the line number from the absolute offset passed in as a parameter
     */
    fun getLineFromOffset(pos: Int): Int {
        if (pos >= content!!.length) {
            if (content[content.length - 1] == '\n') {
                return startingLine + lineOffsets.size
            }
            return startingLine + lineOffsets.size - 1
        }
        val bsearchResult = Arrays.binarySearch(lineOffsets, pos)
        if (bsearchResult >= 0) {
            return max(1.0, (startingLine + bsearchResult).toDouble()).toInt()
        }
        return max(1.0, (startingLine - (bsearchResult + 2)).toDouble()).toInt()
    }

    /**
     * @return the column (1-based and in code points)
     * from the absolute offset passed in as a parameter
     */
    fun getCodePointColumnFromOffset(pos: Int): Int {
        var pos = pos
        if (pos >= content!!.length) return 1
        if (pos == 0) return startingColumn
        val line = getLineFromOffset(pos) - startingLine
        val lineStart = lineOffsets[line]
        val startColumnAdjustment = if (line > 0) 1 else startingColumn
        val unadjustedColumn = pos - lineStart + startColumnAdjustment
        if (!needToCalculateColumns[line]) {
            return unadjustedColumn
        }
        if (Character.isLowSurrogate(content[pos])) --pos
        var result = startColumnAdjustment
        var i = lineStart
        while (i < pos) {
            val ch = content[i]
            if (ch == '\t') {
                result += tabSize - (result - 1) % tabSize
            } else if (Character.isHighSurrogate(ch)) {
                ++result
                ++i
            } else {
                ++result
            }
            i++
        }
        return result
    }

    /**
     * @return the text between startOffset (inclusive)
     * and endOffset(exclusive)
     */
    fun getText(startOffset: Int, endOffset: Int): String {
        val buf = StringBuilder()
        for (offset in startOffset..<endOffset) {
            if (tokenLocationTable[offset] !== IGNORED) {
                buf.append(content!![offset])
            }
        }
        return buf.toString()
    }

    fun cacheToken(tok: Token) {
        if (tok.isInserted) {
            val next = tok.nextCachedToken()
            if (next != null) cacheToken(next)
            return
        }
        val offset = tok.beginOffset
        if (tokenLocationTable[offset] !== IGNORED) {
            tokenOffsets!!.set(offset)
            tokenLocationTable[offset] = tok
        }
    }

    fun uncacheTokens(lastToken: Token) {
        val endOffset = lastToken.endOffset
        if (endOffset < tokenOffsets!!.length()) {
            tokenOffsets.clear(lastToken.endOffset, tokenOffsets.length())
        }
        lastToken.unsetAppendedToken()
    }

    fun nextCachedToken(offset: Int): Token? {
        val nextOffset = tokenOffsets!!.nextSetBit(offset)
        return if (nextOffset != -1) tokenLocationTable[nextOffset] else null
    }

    fun previousCachedToken(offset: Int): Token? {
        val prevOffset = tokenOffsets!!.previousSetBit(offset - 1)
        return if (prevOffset == -1) null else tokenLocationTable[prevOffset]
    }

    private fun createLineOffsetsTable() {
        if (content!!.length == 0) {
            this.lineOffsets = IntArray(0)
            return
        }
        var lineCount = 0
        val length = content.length
        for (i in 0..<length) {
            val ch = content[i]
            if (ch == '\t' || Character.isHighSurrogate(ch)) {
                needToCalculateColumns.set(lineCount)
            }
            if (ch == '\n') {
                lineCount++
            }
        }
        if (content[length - 1] != '\n') {
            lineCount++
        }
        val lineOffsets = IntArray(lineCount)
        lineOffsets[0] = 0
        var index = 1
        for (i in 0..<length) {
            val ch = content[i]
            if (ch == '\n') {
                if (i + 1 == length) break
                lineOffsets[index++] = i + 1
            }
        }
        this.lineOffsets = lineOffsets
    }

    /**
     * @param inputSource just the name of the input source (typically the filename) that
     * will be used in error messages and so on.
     * @param input       the input
     * @param lexState    the lexical state to use
     * @param startingLine
     * The line number at which we are starting for the purposes of location/error messages.
     * In most normal usage, this is 1.
     * @param startingColumn
     * The column number at which we are starting for the purposes of location/error messages.
     * In most normal usages this is 1.
     */
    /**
     * @param inputSource just the name of the input source (typically the filename)
     * that will be used in error messages and so on.
     * @param input       the input
     */
    init {
        this.inputSource = inputSource
        this.content = mungeContent(input, true, false, false, false)
        this.inputSource = inputSource
        createLineOffsetsTable()
        tokenLocationTable = arrayOfNulls(content.length + 1)
        tokenOffsets = BitSet(content.length + 1)
        this.startingLine = startingLine
        this.startingColumn = startingColumn
        switchTo(lexState)
    }

    companion object {
        private val nfaFunctions: Array<NfaFunction?> = SNBTNfaData.getFunctionTableMap(null)
        const val DEFAULT_TAB_SIZE: Int = 1

        // Just a dummy Token value that we put in the tokenLocationTable
        // to indicate that this location in the file is ignored.
        private val IGNORED = Token()
        private val SKIPPED = Token()

        init {
            IGNORED.isUnparsed = true
            SKIPPED.isUnparsed = true
        }

        // Token types that are "regular" tokens that participate in parsing,
        // i.e. declared as TOKEN
        val regularTokens: EnumSet<SNBTConstants.TokenType> = EnumSet.of(
            SNBTConstants.TokenType.EOF,
            SNBTConstants.TokenType.COLON,
            SNBTConstants.TokenType.COMMA,
            SNBTConstants.TokenType.OPEN_BRACKET,
            SNBTConstants.TokenType.CLOSE_BRACKET,
            SNBTConstants.TokenType.OPEN_BRACE,
            SNBTConstants.TokenType.CLOSE_BRACE,
            SNBTConstants.TokenType.BOOLEAN,
            SNBTConstants.TokenType.FLOAT,
            SNBTConstants.TokenType.DOUBLE,
            SNBTConstants.TokenType.INTEGER,
            SNBTConstants.TokenType.LONG,
            SNBTConstants.TokenType.BYTE,
            SNBTConstants.TokenType.SHORT,
            SNBTConstants.TokenType.STRING,
            SNBTConstants.TokenType.B,
            SNBTConstants.TokenType._TOKEN_17,
            SNBTConstants.TokenType.I
        )

        // Token types that do not participate in parsing, a.k.a. "special" tokens in legacy JavaCC,
        // i.e. declared as UNPARSED (or SPECIAL_TOKEN)
        private val unparsedTokens: EnumSet<SNBTConstants.TokenType> = EnumSet.noneOf(
            SNBTConstants.TokenType::class.java
        )

        // Tokens that are skipped, i.e. SKIP 
        val skippedTokens: EnumSet<SNBTConstants.TokenType> = EnumSet.of(SNBTConstants.TokenType.WHITESPACE)

        // Tokens that correspond to a MORE, i.e. that are pending 
        // additional input
        private val moreTokens: EnumSet<SNBTConstants.TokenType> = EnumSet.noneOf(
            SNBTConstants.TokenType::class.java
        )

        // Icky method to handle annoying stuff. Might make this public later if it is
        // needed elsewhere
        private fun mungeContent(
            content: CharSequence,
            preserveTabs: Boolean,
            preserveLines: Boolean,
            javaUnicodeEscape: Boolean,
            ensureFinalEndline: Boolean
        ): String {
            var content = content
            if (preserveTabs && preserveLines && !javaUnicodeEscape) {
                if (ensureFinalEndline) {
                    if (content.length == 0) {
                        content = "\n"
                    } else {
                        val lastChar = content[content.length - 1].code
                        if (lastChar != '\n'.code && lastChar != '\r'.code) {
                            if (content is StringBuilder) {
                                content.append('\n')
                            } else {
                                val buf = StringBuilder(content)
                                buf.append('\n')
                                content = buf.toString()
                            }
                        }
                    }
                }
                return content.toString()
            }
            val buf = StringBuilder()
            // This is just to handle tabs to spaces. If you don't have that setting set, it
            // is really unused.
            var col = 0
            var index = 0
            val contentLength = content.length
            while (index < contentLength) {
                val ch = content[index++]
                if (ch == '\n') {
                    buf.append(ch)
                    col = 0
                } else if (javaUnicodeEscape && ch == '\\' && index < contentLength && content[index] == 'u') {
                    var numPrecedingSlashes = 0
                    for (i in index - 1 downTo 0) {
                        if (content[i] == '\\') numPrecedingSlashes++
                        else break
                    }
                    if (numPrecedingSlashes % 2 == 0) {
                        buf.append('\\')
                        ++col
                        continue
                    }
                    var numConsecutiveUs = 0
                    for (i in index..<contentLength) {
                        if (content[i] == 'u') numConsecutiveUs++
                        else break
                    }
                    val fourHexDigits =
                        content.subSequence(index + numConsecutiveUs, index + numConsecutiveUs + 4).toString()
                    buf.append(fourHexDigits.toInt(16).toChar())
                    index += (numConsecutiveUs + 4)
                    ++col
                } else if (!preserveLines && ch == '\r') {
                    buf.append('\n')
                    col = 0
                    if (index < contentLength && content[index] == '\n') {
                        ++index
                    }
                } else if (ch == '\t' && !preserveTabs) {
                    val spacesToAdd = DEFAULT_TAB_SIZE - col % DEFAULT_TAB_SIZE
                    for (i in 0..<spacesToAdd) {
                        buf.append(' ')
                        col++
                    }
                } else {
                    buf.append(ch)
                    if (!Character.isLowSurrogate(ch)) col++
                }
            }
            if (ensureFinalEndline) {
                if (buf.length == 0) {
                    return "\n"
                }
                val lastChar = buf[buf.length - 1]
                if (lastChar != '\n' && lastChar != '\r') buf.append('\n')
            }
            return buf.toString()
        }

        fun displayChar(ch: Int): String {
            if (ch == '\''.code) return "\'\\'\'"
            if (ch == '\\'.code) return "\'\\\\\'"
            if (ch == '\t'.code) return "\'\\t\'"
            if (ch == '\r'.code) return "\'\\r\'"
            if (ch == '\n'.code) return "\'\\n\'"
            if (ch == '\f'.code) return "\'\\f\'"
            if (ch == ' '.code) return "\' \'"
            if (ch < 128 && !Character.isWhitespace(ch) && !Character.isISOControl(ch)) return "\'" + ch.toChar() + "\'"
            if (ch < 10) return "" + ch
            return "0x" + Integer.toHexString(ch)
        }

        fun addEscapes(str: String): String {
            val retval = StringBuilder()
            for (ch in str.codePoints().toArray()) {
                when (ch) {
                    '\b' -> {
                        retval.append("\\b")
                        continue
                    }

                    '\t' -> {
                        retval.append("\\t")
                        continue
                    }

                    '\n' -> {
                        retval.append("\\n")
                        continue
                    }

                    '\f' -> {
                        retval.append("\\f")
                        continue
                    }

                    '\r' -> {
                        retval.append("\\r")
                        continue
                    }

                    '\"' -> {
                        retval.append("\\\"")
                        continue
                    }

                    '\'' -> {
                        retval.append("\\\'")
                        continue
                    }

                    '\\' -> {
                        retval.append("\\\\")
                        continue
                    }

                    else -> {
                        if (Character.isISOControl(ch)) {
                            val s = "0000" + ch.toString(16)
                            retval.append("\\u" + s.substring(s.length - 4, s.length))
                        } else {
                            retval.appendCodePoint(ch)
                        }
                        continue
                    }
                }
            }
            return retval.toString()
        }

        // Annoying kludge really...
        fun readToEnd(reader: Reader): String {
            try {
                return readFully(reader)
            } catch (ioe: IOException) {
                throw RuntimeException(ioe)
            }
        }

        const val BUF_SIZE: Int = 0x10000

        @Throws(IOException::class)
        fun readFully(reader: Reader): String {
            val block = CharArray(BUF_SIZE)
            var charsRead = reader.read(block)
            if (charsRead < 0) {
                throw IOException("No input")
            } else if (charsRead < BUF_SIZE) {
                val result = CharArray(charsRead)
                System.arraycopy(block, 0, result, 0, charsRead)
                reader.close()
                return String(block, 0, charsRead)
            }
            val buf = StringBuilder()
            buf.append(block)
            do {
                charsRead = reader.read(block)
                if (charsRead > 0) {
                    buf.appendRange(block, 0, charsRead)
                }
            } while (charsRead == BUF_SIZE)
            reader.close()
            return buf.toString()
        }

        /**
         * @param bytes   the raw byte array
         * @param charset The encoding to use to decode the bytes. If this is null, we check for the
         * initial byte order mark (used by Microsoft a lot seemingly)
         * See: [Microsoft docs](https://docs.microsoft.com/es-es/globalization/encoding/byte-order-markc)
         * @return A String taking into account the encoding passed in or in the byte order mark (if it was present).
         * And if no encoding was passed in and no byte-order mark was present, we assume the raw input
         * is in UTF-8.
         */
        @JvmOverloads
        @Throws(CharacterCodingException::class)
        fun stringFromBytes(bytes: ByteArray, charset: Charset? = null): String {
            var charset = charset
            val arrayLength = bytes.size
            if (charset == null) {
                val firstByte = if (arrayLength > 0) java.lang.Byte.toUnsignedInt(bytes[0]) else 1
                val secondByte = if (arrayLength > 1) java.lang.Byte.toUnsignedInt(bytes[1]) else 1
                val thirdByte = if (arrayLength > 2) java.lang.Byte.toUnsignedInt(bytes[2]) else 1
                val fourthByte = if (arrayLength > 3) java.lang.Byte.toUnsignedInt(bytes[3]) else 1
                if (firstByte == 0xEF && secondByte == 0xBB && thirdByte == 0xBF) {
                    return String(bytes, 3, bytes.size - 3, Charset.forName("UTF-8"))
                }
                if (firstByte == 0 && secondByte == 0 && thirdByte == 0xFE && fourthByte == 0xFF) {
                    return String(bytes, 4, bytes.size - 4, Charset.forName("UTF-32BE"))
                }
                if (firstByte == 0xFF && secondByte == 0xFE && thirdByte == 0 && fourthByte == 0) {
                    return String(bytes, 4, bytes.size - 4, Charset.forName("UTF-32LE"))
                }
                if (firstByte == 0xFE && secondByte == 0xFF) {
                    return String(bytes, 2, bytes.size - 2, Charset.forName("UTF-16BE"))
                }
                if (firstByte == 0xFF && secondByte == 0xFE) {
                    return String(bytes, 2, bytes.size - 2, Charset.forName("UTF-16LE"))
                }
                charset = StandardCharsets.UTF_8
            }
            val decoder = charset!!.newDecoder()
            val b = ByteBuffer.wrap(bytes)
            val c = CharBuffer.allocate(bytes.size)
            while (true) {
                val r = decoder.decode(b, c, false)
                if (!r.isError) {
                    break
                }
                if (!r.isMalformed) {
                    r.throwException()
                }
                val n = r.length()
                b.position(b.position() + n)
                for (i in 0..<n) {
                    c.put(0xFFFD.toChar())
                }
            }
            (c as Buffer).limit(c.position())
            (c as Buffer).rewind()
            return c.toString()
            // return new String(bytes, charset);
        }
    }
}


